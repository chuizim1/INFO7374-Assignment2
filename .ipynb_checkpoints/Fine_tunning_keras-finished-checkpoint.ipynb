{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EVOGyFdG3E6"
   },
   "source": [
    "# Fine-tuning  (pretrained on ImageNET) on CIFAR10\n",
    "\n",
    "Here, we present the process of fine-tuning the InceptionResNetV2 network (from [keras.applications](https://keras.io/applications/)).\n",
    "\n",
    "We use InceptionResNetv2 from [keras.applications](https://keras.io/applications/)), which is already pretrained on ImageNET database. Next we add some additional layers in order to train the network on CIFAR10 dataset.\n",
    "\n",
    "We used the [keras](https://keras.io/) python deep learning library.\n",
    "Namely, we follow [keras.applications](https://keras.io/applications/#usage-examples-for-image-classification-models) tutorial.\n",
    "\n",
    "Here is the example to load the InceptionResNetV2 CNN with keras\n",
    "```python\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "model = InceptionResNetV2(include_top=False, weights='imagenet', \\\n",
    "                    input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "```\n",
    "The most important for is to give the paramater\n",
    "```python\n",
    "include_top=False\n",
    "```\n",
    "\n",
    "since it builds the CNN model without the last (top) layer which is responsible to classify ImageNET categorized to 1000 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "WTT68mkZG3E7",
    "outputId": "f2f79946-1270-4e5c-d0a0-69ecec91a6e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available networks =  ['incv2', 'resnet50', 'vgg16', 'vgg19']\n",
      "Selected network:  incv2\n"
     ]
    }
   ],
   "source": [
    "network_names = [ 'incv2' ]\n",
    "\n",
    "print(\"Available networks = \", network_names)\n",
    "cnnid = 0; # int( input(\"Please choose the CNN network [0-{n}]: \".format(n=len(network_names)-1)) )\n",
    "\n",
    "selected_network = network_names[cnnid]\n",
    "print(\"Selected network: \", selected_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9JnTeM9yG3FA",
    "outputId": "86654ff8-6821-4fdd-f96b-9a0790ba405d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#import myutils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfsqDiQDG3FD"
   },
   "source": [
    "# Load CIFAR10 data\n",
    "Here we use [keras.datasets](https://keras.io/datasets/) which is pretty similar to our <tt>myutils.load_CIFAR10_dataset()</tt> procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "6tgmcmVPG3FE",
    "outputId": "3372520c-ea63-483a-ed6e-742b9dcbaeee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "n_training = X_train.shape[0]\n",
    "n_testing = X_test.shape[0]\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test  = y_test.flatten()\n",
    "\n",
    "print( X_train.shape, y_train.shape,  X_test.shape, y_test.shape )\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow( X_train[0]  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhS7-TQ8G3FI"
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMfkjtnQG3FI"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "input_shape = {\n",
    "    'incv2'   : (224,224,3)\n",
    "}[selected_network]\n",
    "\n",
    "def create_model_incv2():\n",
    "    tf_input = Input(shape=input_shape)\n",
    "    base_model = InceptionResNetV2(input_tensor=tf_input, weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(n_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return base_model, model\n",
    "\n",
    "create_model = {\n",
    "    'incv2'    : create_model_incv2,\n",
    "}[selected_network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZtyjEJ3G3FM"
   },
   "source": [
    "# Data generator for tensorflow\n",
    "\n",
    "The feature extraction can process the batches of data. It is common in feeding neural networks in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztAqMDnIG3FN"
   },
   "outputs": [],
   "source": [
    "# tensorflow placeholder for batch of images from CIFAR10 dataset\n",
    "batch_of_images_placeholder = tf.placeholder(\"uint8\", (None, 32, 32, 3))\n",
    "\n",
    "batch_size = {\n",
    "    'incv2'    : 64,\n",
    "}[selected_network]\n",
    "\n",
    "# Inception default size is 299x299\n",
    "tf_resize_op = tf.image.resize_images(batch_of_images_placeholder, (input_shape[:2]), method=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDf7VDb2G3FP"
   },
   "outputs": [],
   "source": [
    "# data generator for tensorflow session\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input as incv2_preprocess_input\n",
    "\n",
    "preprocess_input = {\n",
    "    'incv2'   : incv2_preprocess_input,\n",
    "}[selected_network]\n",
    "\n",
    "def data_generator(sess,data,labels):\n",
    "    def generator():\n",
    "        start = 0\n",
    "        end = start + batch_size\n",
    "        n = data.shape[0]\n",
    "        while True:\n",
    "            batch_of_images_resized = sess.run(tf_resize_op, {batch_of_images_placeholder: data[start:end]})\n",
    "            batch_of_images__preprocessed = preprocess_input(batch_of_images_resized)\n",
    "            batch_of_labels = labels[start:end]\n",
    "            \n",
    "            start += batch_size\n",
    "            end   += batch_size\n",
    "            if start >= n:\n",
    "                start = 0\n",
    "                end = batch_size\n",
    "            yield (batch_of_images__preprocessed, batch_of_labels)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1V0bQRclG3FT"
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuHs2qyfG3FW"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7UReaDcG3Fh"
   },
   "outputs": [],
   "source": [
    "K.set_session(sess)\n",
    "K.set_learning_phase(1)  # 0 - test,  1 - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "gbWjwmuHG3Fi",
    "outputId": "424fae9a-889f-471d-d895-f17fdd5abd09"
   },
   "outputs": [],
   "source": [
    "base_model, model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 14057
    },
    "colab_type": "code",
    "id": "IdOK_BYoG3Fk",
    "outputId": "758c78a7-47c0-460f-cea3-6a18cdfcfc9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed_5b\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 conv2d_13\n",
      "51 conv2d_15\n",
      "52 conv2d_18\n",
      "53 batch_normalization_13\n",
      "54 batch_normalization_15\n",
      "55 batch_normalization_18\n",
      "56 activation_13\n",
      "57 activation_15\n",
      "58 activation_18\n",
      "59 block35_1_mixed\n",
      "60 block35_1_conv\n",
      "61 block35_1\n",
      "62 block35_1_ac\n",
      "63 conv2d_22\n",
      "64 batch_normalization_22\n",
      "65 activation_22\n",
      "66 conv2d_20\n",
      "67 conv2d_23\n",
      "68 batch_normalization_20\n",
      "69 batch_normalization_23\n",
      "70 activation_20\n",
      "71 activation_23\n",
      "72 conv2d_19\n",
      "73 conv2d_21\n",
      "74 conv2d_24\n",
      "75 batch_normalization_19\n",
      "76 batch_normalization_21\n",
      "77 batch_normalization_24\n",
      "78 activation_19\n",
      "79 activation_21\n",
      "80 activation_24\n",
      "81 block35_2_mixed\n",
      "82 block35_2_conv\n",
      "83 block35_2\n",
      "84 block35_2_ac\n",
      "85 conv2d_28\n",
      "86 batch_normalization_28\n",
      "87 activation_28\n",
      "88 conv2d_26\n",
      "89 conv2d_29\n",
      "90 batch_normalization_26\n",
      "91 batch_normalization_29\n",
      "92 activation_26\n",
      "93 activation_29\n",
      "94 conv2d_25\n",
      "95 conv2d_27\n",
      "96 conv2d_30\n",
      "97 batch_normalization_25\n",
      "98 batch_normalization_27\n",
      "99 batch_normalization_30\n",
      "100 activation_25\n",
      "101 activation_27\n",
      "102 activation_30\n",
      "103 block35_3_mixed\n",
      "104 block35_3_conv\n",
      "105 block35_3\n",
      "106 block35_3_ac\n",
      "107 conv2d_34\n",
      "108 batch_normalization_34\n",
      "109 activation_34\n",
      "110 conv2d_32\n",
      "111 conv2d_35\n",
      "112 batch_normalization_32\n",
      "113 batch_normalization_35\n",
      "114 activation_32\n",
      "115 activation_35\n",
      "116 conv2d_31\n",
      "117 conv2d_33\n",
      "118 conv2d_36\n",
      "119 batch_normalization_31\n",
      "120 batch_normalization_33\n",
      "121 batch_normalization_36\n",
      "122 activation_31\n",
      "123 activation_33\n",
      "124 activation_36\n",
      "125 block35_4_mixed\n",
      "126 block35_4_conv\n",
      "127 block35_4\n",
      "128 block35_4_ac\n",
      "129 conv2d_40\n",
      "130 batch_normalization_40\n",
      "131 activation_40\n",
      "132 conv2d_38\n",
      "133 conv2d_41\n",
      "134 batch_normalization_38\n",
      "135 batch_normalization_41\n",
      "136 activation_38\n",
      "137 activation_41\n",
      "138 conv2d_37\n",
      "139 conv2d_39\n",
      "140 conv2d_42\n",
      "141 batch_normalization_37\n",
      "142 batch_normalization_39\n",
      "143 batch_normalization_42\n",
      "144 activation_37\n",
      "145 activation_39\n",
      "146 activation_42\n",
      "147 block35_5_mixed\n",
      "148 block35_5_conv\n",
      "149 block35_5\n",
      "150 block35_5_ac\n",
      "151 conv2d_46\n",
      "152 batch_normalization_46\n",
      "153 activation_46\n",
      "154 conv2d_44\n",
      "155 conv2d_47\n",
      "156 batch_normalization_44\n",
      "157 batch_normalization_47\n",
      "158 activation_44\n",
      "159 activation_47\n",
      "160 conv2d_43\n",
      "161 conv2d_45\n",
      "162 conv2d_48\n",
      "163 batch_normalization_43\n",
      "164 batch_normalization_45\n",
      "165 batch_normalization_48\n",
      "166 activation_43\n",
      "167 activation_45\n",
      "168 activation_48\n",
      "169 block35_6_mixed\n",
      "170 block35_6_conv\n",
      "171 block35_6\n",
      "172 block35_6_ac\n",
      "173 conv2d_52\n",
      "174 batch_normalization_52\n",
      "175 activation_52\n",
      "176 conv2d_50\n",
      "177 conv2d_53\n",
      "178 batch_normalization_50\n",
      "179 batch_normalization_53\n",
      "180 activation_50\n",
      "181 activation_53\n",
      "182 conv2d_49\n",
      "183 conv2d_51\n",
      "184 conv2d_54\n",
      "185 batch_normalization_49\n",
      "186 batch_normalization_51\n",
      "187 batch_normalization_54\n",
      "188 activation_49\n",
      "189 activation_51\n",
      "190 activation_54\n",
      "191 block35_7_mixed\n",
      "192 block35_7_conv\n",
      "193 block35_7\n",
      "194 block35_7_ac\n",
      "195 conv2d_58\n",
      "196 batch_normalization_58\n",
      "197 activation_58\n",
      "198 conv2d_56\n",
      "199 conv2d_59\n",
      "200 batch_normalization_56\n",
      "201 batch_normalization_59\n",
      "202 activation_56\n",
      "203 activation_59\n",
      "204 conv2d_55\n",
      "205 conv2d_57\n",
      "206 conv2d_60\n",
      "207 batch_normalization_55\n",
      "208 batch_normalization_57\n",
      "209 batch_normalization_60\n",
      "210 activation_55\n",
      "211 activation_57\n",
      "212 activation_60\n",
      "213 block35_8_mixed\n",
      "214 block35_8_conv\n",
      "215 block35_8\n",
      "216 block35_8_ac\n",
      "217 conv2d_64\n",
      "218 batch_normalization_64\n",
      "219 activation_64\n",
      "220 conv2d_62\n",
      "221 conv2d_65\n",
      "222 batch_normalization_62\n",
      "223 batch_normalization_65\n",
      "224 activation_62\n",
      "225 activation_65\n",
      "226 conv2d_61\n",
      "227 conv2d_63\n",
      "228 conv2d_66\n",
      "229 batch_normalization_61\n",
      "230 batch_normalization_63\n",
      "231 batch_normalization_66\n",
      "232 activation_61\n",
      "233 activation_63\n",
      "234 activation_66\n",
      "235 block35_9_mixed\n",
      "236 block35_9_conv\n",
      "237 block35_9\n",
      "238 block35_9_ac\n",
      "239 conv2d_70\n",
      "240 batch_normalization_70\n",
      "241 activation_70\n",
      "242 conv2d_68\n",
      "243 conv2d_71\n",
      "244 batch_normalization_68\n",
      "245 batch_normalization_71\n",
      "246 activation_68\n",
      "247 activation_71\n",
      "248 conv2d_67\n",
      "249 conv2d_69\n",
      "250 conv2d_72\n",
      "251 batch_normalization_67\n",
      "252 batch_normalization_69\n",
      "253 batch_normalization_72\n",
      "254 activation_67\n",
      "255 activation_69\n",
      "256 activation_72\n",
      "257 block35_10_mixed\n",
      "258 block35_10_conv\n",
      "259 block35_10\n",
      "260 block35_10_ac\n",
      "261 conv2d_74\n",
      "262 batch_normalization_74\n",
      "263 activation_74\n",
      "264 conv2d_75\n",
      "265 batch_normalization_75\n",
      "266 activation_75\n",
      "267 conv2d_73\n",
      "268 conv2d_76\n",
      "269 batch_normalization_73\n",
      "270 batch_normalization_76\n",
      "271 activation_73\n",
      "272 activation_76\n",
      "273 max_pooling2d_3\n",
      "274 mixed_6a\n",
      "275 conv2d_78\n",
      "276 batch_normalization_78\n",
      "277 activation_78\n",
      "278 conv2d_79\n",
      "279 batch_normalization_79\n",
      "280 activation_79\n",
      "281 conv2d_77\n",
      "282 conv2d_80\n",
      "283 batch_normalization_77\n",
      "284 batch_normalization_80\n",
      "285 activation_77\n",
      "286 activation_80\n",
      "287 block17_1_mixed\n",
      "288 block17_1_conv\n",
      "289 block17_1\n",
      "290 block17_1_ac\n",
      "291 conv2d_82\n",
      "292 batch_normalization_82\n",
      "293 activation_82\n",
      "294 conv2d_83\n",
      "295 batch_normalization_83\n",
      "296 activation_83\n",
      "297 conv2d_81\n",
      "298 conv2d_84\n",
      "299 batch_normalization_81\n",
      "300 batch_normalization_84\n",
      "301 activation_81\n",
      "302 activation_84\n",
      "303 block17_2_mixed\n",
      "304 block17_2_conv\n",
      "305 block17_2\n",
      "306 block17_2_ac\n",
      "307 conv2d_86\n",
      "308 batch_normalization_86\n",
      "309 activation_86\n",
      "310 conv2d_87\n",
      "311 batch_normalization_87\n",
      "312 activation_87\n",
      "313 conv2d_85\n",
      "314 conv2d_88\n",
      "315 batch_normalization_85\n",
      "316 batch_normalization_88\n",
      "317 activation_85\n",
      "318 activation_88\n",
      "319 block17_3_mixed\n",
      "320 block17_3_conv\n",
      "321 block17_3\n",
      "322 block17_3_ac\n",
      "323 conv2d_90\n",
      "324 batch_normalization_90\n",
      "325 activation_90\n",
      "326 conv2d_91\n",
      "327 batch_normalization_91\n",
      "328 activation_91\n",
      "329 conv2d_89\n",
      "330 conv2d_92\n",
      "331 batch_normalization_89\n",
      "332 batch_normalization_92\n",
      "333 activation_89\n",
      "334 activation_92\n",
      "335 block17_4_mixed\n",
      "336 block17_4_conv\n",
      "337 block17_4\n",
      "338 block17_4_ac\n",
      "339 conv2d_94\n",
      "340 batch_normalization_94\n",
      "341 activation_94\n",
      "342 conv2d_95\n",
      "343 batch_normalization_95\n",
      "344 activation_95\n",
      "345 conv2d_93\n",
      "346 conv2d_96\n",
      "347 batch_normalization_93\n",
      "348 batch_normalization_96\n",
      "349 activation_93\n",
      "350 activation_96\n",
      "351 block17_5_mixed\n",
      "352 block17_5_conv\n",
      "353 block17_5\n",
      "354 block17_5_ac\n",
      "355 conv2d_98\n",
      "356 batch_normalization_98\n",
      "357 activation_98\n",
      "358 conv2d_99\n",
      "359 batch_normalization_99\n",
      "360 activation_99\n",
      "361 conv2d_97\n",
      "362 conv2d_100\n",
      "363 batch_normalization_97\n",
      "364 batch_normalization_100\n",
      "365 activation_97\n",
      "366 activation_100\n",
      "367 block17_6_mixed\n",
      "368 block17_6_conv\n",
      "369 block17_6\n",
      "370 block17_6_ac\n",
      "371 conv2d_102\n",
      "372 batch_normalization_102\n",
      "373 activation_102\n",
      "374 conv2d_103\n",
      "375 batch_normalization_103\n",
      "376 activation_103\n",
      "377 conv2d_101\n",
      "378 conv2d_104\n",
      "379 batch_normalization_101\n",
      "380 batch_normalization_104\n",
      "381 activation_101\n",
      "382 activation_104\n",
      "383 block17_7_mixed\n",
      "384 block17_7_conv\n",
      "385 block17_7\n",
      "386 block17_7_ac\n",
      "387 conv2d_106\n",
      "388 batch_normalization_106\n",
      "389 activation_106\n",
      "390 conv2d_107\n",
      "391 batch_normalization_107\n",
      "392 activation_107\n",
      "393 conv2d_105\n",
      "394 conv2d_108\n",
      "395 batch_normalization_105\n",
      "396 batch_normalization_108\n",
      "397 activation_105\n",
      "398 activation_108\n",
      "399 block17_8_mixed\n",
      "400 block17_8_conv\n",
      "401 block17_8\n",
      "402 block17_8_ac\n",
      "403 conv2d_110\n",
      "404 batch_normalization_110\n",
      "405 activation_110\n",
      "406 conv2d_111\n",
      "407 batch_normalization_111\n",
      "408 activation_111\n",
      "409 conv2d_109\n",
      "410 conv2d_112\n",
      "411 batch_normalization_109\n",
      "412 batch_normalization_112\n",
      "413 activation_109\n",
      "414 activation_112\n",
      "415 block17_9_mixed\n",
      "416 block17_9_conv\n",
      "417 block17_9\n",
      "418 block17_9_ac\n",
      "419 conv2d_114\n",
      "420 batch_normalization_114\n",
      "421 activation_114\n",
      "422 conv2d_115\n",
      "423 batch_normalization_115\n",
      "424 activation_115\n",
      "425 conv2d_113\n",
      "426 conv2d_116\n",
      "427 batch_normalization_113\n",
      "428 batch_normalization_116\n",
      "429 activation_113\n",
      "430 activation_116\n",
      "431 block17_10_mixed\n",
      "432 block17_10_conv\n",
      "433 block17_10\n",
      "434 block17_10_ac\n",
      "435 conv2d_118\n",
      "436 batch_normalization_118\n",
      "437 activation_118\n",
      "438 conv2d_119\n",
      "439 batch_normalization_119\n",
      "440 activation_119\n",
      "441 conv2d_117\n",
      "442 conv2d_120\n",
      "443 batch_normalization_117\n",
      "444 batch_normalization_120\n",
      "445 activation_117\n",
      "446 activation_120\n",
      "447 block17_11_mixed\n",
      "448 block17_11_conv\n",
      "449 block17_11\n",
      "450 block17_11_ac\n",
      "451 conv2d_122\n",
      "452 batch_normalization_122\n",
      "453 activation_122\n",
      "454 conv2d_123\n",
      "455 batch_normalization_123\n",
      "456 activation_123\n",
      "457 conv2d_121\n",
      "458 conv2d_124\n",
      "459 batch_normalization_121\n",
      "460 batch_normalization_124\n",
      "461 activation_121\n",
      "462 activation_124\n",
      "463 block17_12_mixed\n",
      "464 block17_12_conv\n",
      "465 block17_12\n",
      "466 block17_12_ac\n",
      "467 conv2d_126\n",
      "468 batch_normalization_126\n",
      "469 activation_126\n",
      "470 conv2d_127\n",
      "471 batch_normalization_127\n",
      "472 activation_127\n",
      "473 conv2d_125\n",
      "474 conv2d_128\n",
      "475 batch_normalization_125\n",
      "476 batch_normalization_128\n",
      "477 activation_125\n",
      "478 activation_128\n",
      "479 block17_13_mixed\n",
      "480 block17_13_conv\n",
      "481 block17_13\n",
      "482 block17_13_ac\n",
      "483 conv2d_130\n",
      "484 batch_normalization_130\n",
      "485 activation_130\n",
      "486 conv2d_131\n",
      "487 batch_normalization_131\n",
      "488 activation_131\n",
      "489 conv2d_129\n",
      "490 conv2d_132\n",
      "491 batch_normalization_129\n",
      "492 batch_normalization_132\n",
      "493 activation_129\n",
      "494 activation_132\n",
      "495 block17_14_mixed\n",
      "496 block17_14_conv\n",
      "497 block17_14\n",
      "498 block17_14_ac\n",
      "499 conv2d_134\n",
      "500 batch_normalization_134\n",
      "501 activation_134\n",
      "502 conv2d_135\n",
      "503 batch_normalization_135\n",
      "504 activation_135\n",
      "505 conv2d_133\n",
      "506 conv2d_136\n",
      "507 batch_normalization_133\n",
      "508 batch_normalization_136\n",
      "509 activation_133\n",
      "510 activation_136\n",
      "511 block17_15_mixed\n",
      "512 block17_15_conv\n",
      "513 block17_15\n",
      "514 block17_15_ac\n",
      "515 conv2d_138\n",
      "516 batch_normalization_138\n",
      "517 activation_138\n",
      "518 conv2d_139\n",
      "519 batch_normalization_139\n",
      "520 activation_139\n",
      "521 conv2d_137\n",
      "522 conv2d_140\n",
      "523 batch_normalization_137\n",
      "524 batch_normalization_140\n",
      "525 activation_137\n",
      "526 activation_140\n",
      "527 block17_16_mixed\n",
      "528 block17_16_conv\n",
      "529 block17_16\n",
      "530 block17_16_ac\n",
      "531 conv2d_142\n",
      "532 batch_normalization_142\n",
      "533 activation_142\n",
      "534 conv2d_143\n",
      "535 batch_normalization_143\n",
      "536 activation_143\n",
      "537 conv2d_141\n",
      "538 conv2d_144\n",
      "539 batch_normalization_141\n",
      "540 batch_normalization_144\n",
      "541 activation_141\n",
      "542 activation_144\n",
      "543 block17_17_mixed\n",
      "544 block17_17_conv\n",
      "545 block17_17\n",
      "546 block17_17_ac\n",
      "547 conv2d_146\n",
      "548 batch_normalization_146\n",
      "549 activation_146\n",
      "550 conv2d_147\n",
      "551 batch_normalization_147\n",
      "552 activation_147\n",
      "553 conv2d_145\n",
      "554 conv2d_148\n",
      "555 batch_normalization_145\n",
      "556 batch_normalization_148\n",
      "557 activation_145\n",
      "558 activation_148\n",
      "559 block17_18_mixed\n",
      "560 block17_18_conv\n",
      "561 block17_18\n",
      "562 block17_18_ac\n",
      "563 conv2d_150\n",
      "564 batch_normalization_150\n",
      "565 activation_150\n",
      "566 conv2d_151\n",
      "567 batch_normalization_151\n",
      "568 activation_151\n",
      "569 conv2d_149\n",
      "570 conv2d_152\n",
      "571 batch_normalization_149\n",
      "572 batch_normalization_152\n",
      "573 activation_149\n",
      "574 activation_152\n",
      "575 block17_19_mixed\n",
      "576 block17_19_conv\n",
      "577 block17_19\n",
      "578 block17_19_ac\n",
      "579 conv2d_154\n",
      "580 batch_normalization_154\n",
      "581 activation_154\n",
      "582 conv2d_155\n",
      "583 batch_normalization_155\n",
      "584 activation_155\n",
      "585 conv2d_153\n",
      "586 conv2d_156\n",
      "587 batch_normalization_153\n",
      "588 batch_normalization_156\n",
      "589 activation_153\n",
      "590 activation_156\n",
      "591 block17_20_mixed\n",
      "592 block17_20_conv\n",
      "593 block17_20\n",
      "594 block17_20_ac\n",
      "595 conv2d_161\n",
      "596 batch_normalization_161\n",
      "597 activation_161\n",
      "598 conv2d_157\n",
      "599 conv2d_159\n",
      "600 conv2d_162\n",
      "601 batch_normalization_157\n",
      "602 batch_normalization_159\n",
      "603 batch_normalization_162\n",
      "604 activation_157\n",
      "605 activation_159\n",
      "606 activation_162\n",
      "607 conv2d_158\n",
      "608 conv2d_160\n",
      "609 conv2d_163\n",
      "610 batch_normalization_158\n",
      "611 batch_normalization_160\n",
      "612 batch_normalization_163\n",
      "613 activation_158\n",
      "614 activation_160\n",
      "615 activation_163\n",
      "616 max_pooling2d_4\n",
      "617 mixed_7a\n",
      "618 conv2d_165\n",
      "619 batch_normalization_165\n",
      "620 activation_165\n",
      "621 conv2d_166\n",
      "622 batch_normalization_166\n",
      "623 activation_166\n",
      "624 conv2d_164\n",
      "625 conv2d_167\n",
      "626 batch_normalization_164\n",
      "627 batch_normalization_167\n",
      "628 activation_164\n",
      "629 activation_167\n",
      "630 block8_1_mixed\n",
      "631 block8_1_conv\n",
      "632 block8_1\n",
      "633 block8_1_ac\n",
      "634 conv2d_169\n",
      "635 batch_normalization_169\n",
      "636 activation_169\n",
      "637 conv2d_170\n",
      "638 batch_normalization_170\n",
      "639 activation_170\n",
      "640 conv2d_168\n",
      "641 conv2d_171\n",
      "642 batch_normalization_168\n",
      "643 batch_normalization_171\n",
      "644 activation_168\n",
      "645 activation_171\n",
      "646 block8_2_mixed\n",
      "647 block8_2_conv\n",
      "648 block8_2\n",
      "649 block8_2_ac\n",
      "650 conv2d_173\n",
      "651 batch_normalization_173\n",
      "652 activation_173\n",
      "653 conv2d_174\n",
      "654 batch_normalization_174\n",
      "655 activation_174\n",
      "656 conv2d_172\n",
      "657 conv2d_175\n",
      "658 batch_normalization_172\n",
      "659 batch_normalization_175\n",
      "660 activation_172\n",
      "661 activation_175\n",
      "662 block8_3_mixed\n",
      "663 block8_3_conv\n",
      "664 block8_3\n",
      "665 block8_3_ac\n",
      "666 conv2d_177\n",
      "667 batch_normalization_177\n",
      "668 activation_177\n",
      "669 conv2d_178\n",
      "670 batch_normalization_178\n",
      "671 activation_178\n",
      "672 conv2d_176\n",
      "673 conv2d_179\n",
      "674 batch_normalization_176\n",
      "675 batch_normalization_179\n",
      "676 activation_176\n",
      "677 activation_179\n",
      "678 block8_4_mixed\n",
      "679 block8_4_conv\n",
      "680 block8_4\n",
      "681 block8_4_ac\n",
      "682 conv2d_181\n",
      "683 batch_normalization_181\n",
      "684 activation_181\n",
      "685 conv2d_182\n",
      "686 batch_normalization_182\n",
      "687 activation_182\n",
      "688 conv2d_180\n",
      "689 conv2d_183\n",
      "690 batch_normalization_180\n",
      "691 batch_normalization_183\n",
      "692 activation_180\n",
      "693 activation_183\n",
      "694 block8_5_mixed\n",
      "695 block8_5_conv\n",
      "696 block8_5\n",
      "697 block8_5_ac\n",
      "698 conv2d_185\n",
      "699 batch_normalization_185\n",
      "700 activation_185\n",
      "701 conv2d_186\n",
      "702 batch_normalization_186\n",
      "703 activation_186\n",
      "704 conv2d_184\n",
      "705 conv2d_187\n",
      "706 batch_normalization_184\n",
      "707 batch_normalization_187\n",
      "708 activation_184\n",
      "709 activation_187\n",
      "710 block8_6_mixed\n",
      "711 block8_6_conv\n",
      "712 block8_6\n",
      "713 block8_6_ac\n",
      "714 conv2d_189\n",
      "715 batch_normalization_189\n",
      "716 activation_189\n",
      "717 conv2d_190\n",
      "718 batch_normalization_190\n",
      "719 activation_190\n",
      "720 conv2d_188\n",
      "721 conv2d_191\n",
      "722 batch_normalization_188\n",
      "723 batch_normalization_191\n",
      "724 activation_188\n",
      "725 activation_191\n",
      "726 block8_7_mixed\n",
      "727 block8_7_conv\n",
      "728 block8_7\n",
      "729 block8_7_ac\n",
      "730 conv2d_193\n",
      "731 batch_normalization_193\n",
      "732 activation_193\n",
      "733 conv2d_194\n",
      "734 batch_normalization_194\n",
      "735 activation_194\n",
      "736 conv2d_192\n",
      "737 conv2d_195\n",
      "738 batch_normalization_192\n",
      "739 batch_normalization_195\n",
      "740 activation_192\n",
      "741 activation_195\n",
      "742 block8_8_mixed\n",
      "743 block8_8_conv\n",
      "744 block8_8\n",
      "745 block8_8_ac\n",
      "746 conv2d_197\n",
      "747 batch_normalization_197\n",
      "748 activation_197\n",
      "749 conv2d_198\n",
      "750 batch_normalization_198\n",
      "751 activation_198\n",
      "752 conv2d_196\n",
      "753 conv2d_199\n",
      "754 batch_normalization_196\n",
      "755 batch_normalization_199\n",
      "756 activation_196\n",
      "757 activation_199\n",
      "758 block8_9_mixed\n",
      "759 block8_9_conv\n",
      "760 block8_9\n",
      "761 block8_9_ac\n",
      "762 conv2d_201\n",
      "763 batch_normalization_201\n",
      "764 activation_201\n",
      "765 conv2d_202\n",
      "766 batch_normalization_202\n",
      "767 activation_202\n",
      "768 conv2d_200\n",
      "769 conv2d_203\n",
      "770 batch_normalization_200\n",
      "771 batch_normalization_203\n",
      "772 activation_200\n",
      "773 activation_203\n",
      "774 block8_10_mixed\n",
      "775 block8_10_conv\n",
      "776 block8_10\n",
      "777 conv_7b\n",
      "778 conv_7b_bn\n",
      "779 conv_7b_ac\n"
     ]
    }
   ],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 14111
    },
    "colab_type": "code",
    "id": "i9es5uFFG3Fn",
    "outputId": "0f11d9c7-eced-4e9d-c347-f12c00df7294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed_5b\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 conv2d_13\n",
      "51 conv2d_15\n",
      "52 conv2d_18\n",
      "53 batch_normalization_13\n",
      "54 batch_normalization_15\n",
      "55 batch_normalization_18\n",
      "56 activation_13\n",
      "57 activation_15\n",
      "58 activation_18\n",
      "59 block35_1_mixed\n",
      "60 block35_1_conv\n",
      "61 block35_1\n",
      "62 block35_1_ac\n",
      "63 conv2d_22\n",
      "64 batch_normalization_22\n",
      "65 activation_22\n",
      "66 conv2d_20\n",
      "67 conv2d_23\n",
      "68 batch_normalization_20\n",
      "69 batch_normalization_23\n",
      "70 activation_20\n",
      "71 activation_23\n",
      "72 conv2d_19\n",
      "73 conv2d_21\n",
      "74 conv2d_24\n",
      "75 batch_normalization_19\n",
      "76 batch_normalization_21\n",
      "77 batch_normalization_24\n",
      "78 activation_19\n",
      "79 activation_21\n",
      "80 activation_24\n",
      "81 block35_2_mixed\n",
      "82 block35_2_conv\n",
      "83 block35_2\n",
      "84 block35_2_ac\n",
      "85 conv2d_28\n",
      "86 batch_normalization_28\n",
      "87 activation_28\n",
      "88 conv2d_26\n",
      "89 conv2d_29\n",
      "90 batch_normalization_26\n",
      "91 batch_normalization_29\n",
      "92 activation_26\n",
      "93 activation_29\n",
      "94 conv2d_25\n",
      "95 conv2d_27\n",
      "96 conv2d_30\n",
      "97 batch_normalization_25\n",
      "98 batch_normalization_27\n",
      "99 batch_normalization_30\n",
      "100 activation_25\n",
      "101 activation_27\n",
      "102 activation_30\n",
      "103 block35_3_mixed\n",
      "104 block35_3_conv\n",
      "105 block35_3\n",
      "106 block35_3_ac\n",
      "107 conv2d_34\n",
      "108 batch_normalization_34\n",
      "109 activation_34\n",
      "110 conv2d_32\n",
      "111 conv2d_35\n",
      "112 batch_normalization_32\n",
      "113 batch_normalization_35\n",
      "114 activation_32\n",
      "115 activation_35\n",
      "116 conv2d_31\n",
      "117 conv2d_33\n",
      "118 conv2d_36\n",
      "119 batch_normalization_31\n",
      "120 batch_normalization_33\n",
      "121 batch_normalization_36\n",
      "122 activation_31\n",
      "123 activation_33\n",
      "124 activation_36\n",
      "125 block35_4_mixed\n",
      "126 block35_4_conv\n",
      "127 block35_4\n",
      "128 block35_4_ac\n",
      "129 conv2d_40\n",
      "130 batch_normalization_40\n",
      "131 activation_40\n",
      "132 conv2d_38\n",
      "133 conv2d_41\n",
      "134 batch_normalization_38\n",
      "135 batch_normalization_41\n",
      "136 activation_38\n",
      "137 activation_41\n",
      "138 conv2d_37\n",
      "139 conv2d_39\n",
      "140 conv2d_42\n",
      "141 batch_normalization_37\n",
      "142 batch_normalization_39\n",
      "143 batch_normalization_42\n",
      "144 activation_37\n",
      "145 activation_39\n",
      "146 activation_42\n",
      "147 block35_5_mixed\n",
      "148 block35_5_conv\n",
      "149 block35_5\n",
      "150 block35_5_ac\n",
      "151 conv2d_46\n",
      "152 batch_normalization_46\n",
      "153 activation_46\n",
      "154 conv2d_44\n",
      "155 conv2d_47\n",
      "156 batch_normalization_44\n",
      "157 batch_normalization_47\n",
      "158 activation_44\n",
      "159 activation_47\n",
      "160 conv2d_43\n",
      "161 conv2d_45\n",
      "162 conv2d_48\n",
      "163 batch_normalization_43\n",
      "164 batch_normalization_45\n",
      "165 batch_normalization_48\n",
      "166 activation_43\n",
      "167 activation_45\n",
      "168 activation_48\n",
      "169 block35_6_mixed\n",
      "170 block35_6_conv\n",
      "171 block35_6\n",
      "172 block35_6_ac\n",
      "173 conv2d_52\n",
      "174 batch_normalization_52\n",
      "175 activation_52\n",
      "176 conv2d_50\n",
      "177 conv2d_53\n",
      "178 batch_normalization_50\n",
      "179 batch_normalization_53\n",
      "180 activation_50\n",
      "181 activation_53\n",
      "182 conv2d_49\n",
      "183 conv2d_51\n",
      "184 conv2d_54\n",
      "185 batch_normalization_49\n",
      "186 batch_normalization_51\n",
      "187 batch_normalization_54\n",
      "188 activation_49\n",
      "189 activation_51\n",
      "190 activation_54\n",
      "191 block35_7_mixed\n",
      "192 block35_7_conv\n",
      "193 block35_7\n",
      "194 block35_7_ac\n",
      "195 conv2d_58\n",
      "196 batch_normalization_58\n",
      "197 activation_58\n",
      "198 conv2d_56\n",
      "199 conv2d_59\n",
      "200 batch_normalization_56\n",
      "201 batch_normalization_59\n",
      "202 activation_56\n",
      "203 activation_59\n",
      "204 conv2d_55\n",
      "205 conv2d_57\n",
      "206 conv2d_60\n",
      "207 batch_normalization_55\n",
      "208 batch_normalization_57\n",
      "209 batch_normalization_60\n",
      "210 activation_55\n",
      "211 activation_57\n",
      "212 activation_60\n",
      "213 block35_8_mixed\n",
      "214 block35_8_conv\n",
      "215 block35_8\n",
      "216 block35_8_ac\n",
      "217 conv2d_64\n",
      "218 batch_normalization_64\n",
      "219 activation_64\n",
      "220 conv2d_62\n",
      "221 conv2d_65\n",
      "222 batch_normalization_62\n",
      "223 batch_normalization_65\n",
      "224 activation_62\n",
      "225 activation_65\n",
      "226 conv2d_61\n",
      "227 conv2d_63\n",
      "228 conv2d_66\n",
      "229 batch_normalization_61\n",
      "230 batch_normalization_63\n",
      "231 batch_normalization_66\n",
      "232 activation_61\n",
      "233 activation_63\n",
      "234 activation_66\n",
      "235 block35_9_mixed\n",
      "236 block35_9_conv\n",
      "237 block35_9\n",
      "238 block35_9_ac\n",
      "239 conv2d_70\n",
      "240 batch_normalization_70\n",
      "241 activation_70\n",
      "242 conv2d_68\n",
      "243 conv2d_71\n",
      "244 batch_normalization_68\n",
      "245 batch_normalization_71\n",
      "246 activation_68\n",
      "247 activation_71\n",
      "248 conv2d_67\n",
      "249 conv2d_69\n",
      "250 conv2d_72\n",
      "251 batch_normalization_67\n",
      "252 batch_normalization_69\n",
      "253 batch_normalization_72\n",
      "254 activation_67\n",
      "255 activation_69\n",
      "256 activation_72\n",
      "257 block35_10_mixed\n",
      "258 block35_10_conv\n",
      "259 block35_10\n",
      "260 block35_10_ac\n",
      "261 conv2d_74\n",
      "262 batch_normalization_74\n",
      "263 activation_74\n",
      "264 conv2d_75\n",
      "265 batch_normalization_75\n",
      "266 activation_75\n",
      "267 conv2d_73\n",
      "268 conv2d_76\n",
      "269 batch_normalization_73\n",
      "270 batch_normalization_76\n",
      "271 activation_73\n",
      "272 activation_76\n",
      "273 max_pooling2d_3\n",
      "274 mixed_6a\n",
      "275 conv2d_78\n",
      "276 batch_normalization_78\n",
      "277 activation_78\n",
      "278 conv2d_79\n",
      "279 batch_normalization_79\n",
      "280 activation_79\n",
      "281 conv2d_77\n",
      "282 conv2d_80\n",
      "283 batch_normalization_77\n",
      "284 batch_normalization_80\n",
      "285 activation_77\n",
      "286 activation_80\n",
      "287 block17_1_mixed\n",
      "288 block17_1_conv\n",
      "289 block17_1\n",
      "290 block17_1_ac\n",
      "291 conv2d_82\n",
      "292 batch_normalization_82\n",
      "293 activation_82\n",
      "294 conv2d_83\n",
      "295 batch_normalization_83\n",
      "296 activation_83\n",
      "297 conv2d_81\n",
      "298 conv2d_84\n",
      "299 batch_normalization_81\n",
      "300 batch_normalization_84\n",
      "301 activation_81\n",
      "302 activation_84\n",
      "303 block17_2_mixed\n",
      "304 block17_2_conv\n",
      "305 block17_2\n",
      "306 block17_2_ac\n",
      "307 conv2d_86\n",
      "308 batch_normalization_86\n",
      "309 activation_86\n",
      "310 conv2d_87\n",
      "311 batch_normalization_87\n",
      "312 activation_87\n",
      "313 conv2d_85\n",
      "314 conv2d_88\n",
      "315 batch_normalization_85\n",
      "316 batch_normalization_88\n",
      "317 activation_85\n",
      "318 activation_88\n",
      "319 block17_3_mixed\n",
      "320 block17_3_conv\n",
      "321 block17_3\n",
      "322 block17_3_ac\n",
      "323 conv2d_90\n",
      "324 batch_normalization_90\n",
      "325 activation_90\n",
      "326 conv2d_91\n",
      "327 batch_normalization_91\n",
      "328 activation_91\n",
      "329 conv2d_89\n",
      "330 conv2d_92\n",
      "331 batch_normalization_89\n",
      "332 batch_normalization_92\n",
      "333 activation_89\n",
      "334 activation_92\n",
      "335 block17_4_mixed\n",
      "336 block17_4_conv\n",
      "337 block17_4\n",
      "338 block17_4_ac\n",
      "339 conv2d_94\n",
      "340 batch_normalization_94\n",
      "341 activation_94\n",
      "342 conv2d_95\n",
      "343 batch_normalization_95\n",
      "344 activation_95\n",
      "345 conv2d_93\n",
      "346 conv2d_96\n",
      "347 batch_normalization_93\n",
      "348 batch_normalization_96\n",
      "349 activation_93\n",
      "350 activation_96\n",
      "351 block17_5_mixed\n",
      "352 block17_5_conv\n",
      "353 block17_5\n",
      "354 block17_5_ac\n",
      "355 conv2d_98\n",
      "356 batch_normalization_98\n",
      "357 activation_98\n",
      "358 conv2d_99\n",
      "359 batch_normalization_99\n",
      "360 activation_99\n",
      "361 conv2d_97\n",
      "362 conv2d_100\n",
      "363 batch_normalization_97\n",
      "364 batch_normalization_100\n",
      "365 activation_97\n",
      "366 activation_100\n",
      "367 block17_6_mixed\n",
      "368 block17_6_conv\n",
      "369 block17_6\n",
      "370 block17_6_ac\n",
      "371 conv2d_102\n",
      "372 batch_normalization_102\n",
      "373 activation_102\n",
      "374 conv2d_103\n",
      "375 batch_normalization_103\n",
      "376 activation_103\n",
      "377 conv2d_101\n",
      "378 conv2d_104\n",
      "379 batch_normalization_101\n",
      "380 batch_normalization_104\n",
      "381 activation_101\n",
      "382 activation_104\n",
      "383 block17_7_mixed\n",
      "384 block17_7_conv\n",
      "385 block17_7\n",
      "386 block17_7_ac\n",
      "387 conv2d_106\n",
      "388 batch_normalization_106\n",
      "389 activation_106\n",
      "390 conv2d_107\n",
      "391 batch_normalization_107\n",
      "392 activation_107\n",
      "393 conv2d_105\n",
      "394 conv2d_108\n",
      "395 batch_normalization_105\n",
      "396 batch_normalization_108\n",
      "397 activation_105\n",
      "398 activation_108\n",
      "399 block17_8_mixed\n",
      "400 block17_8_conv\n",
      "401 block17_8\n",
      "402 block17_8_ac\n",
      "403 conv2d_110\n",
      "404 batch_normalization_110\n",
      "405 activation_110\n",
      "406 conv2d_111\n",
      "407 batch_normalization_111\n",
      "408 activation_111\n",
      "409 conv2d_109\n",
      "410 conv2d_112\n",
      "411 batch_normalization_109\n",
      "412 batch_normalization_112\n",
      "413 activation_109\n",
      "414 activation_112\n",
      "415 block17_9_mixed\n",
      "416 block17_9_conv\n",
      "417 block17_9\n",
      "418 block17_9_ac\n",
      "419 conv2d_114\n",
      "420 batch_normalization_114\n",
      "421 activation_114\n",
      "422 conv2d_115\n",
      "423 batch_normalization_115\n",
      "424 activation_115\n",
      "425 conv2d_113\n",
      "426 conv2d_116\n",
      "427 batch_normalization_113\n",
      "428 batch_normalization_116\n",
      "429 activation_113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430 activation_116\n",
      "431 block17_10_mixed\n",
      "432 block17_10_conv\n",
      "433 block17_10\n",
      "434 block17_10_ac\n",
      "435 conv2d_118\n",
      "436 batch_normalization_118\n",
      "437 activation_118\n",
      "438 conv2d_119\n",
      "439 batch_normalization_119\n",
      "440 activation_119\n",
      "441 conv2d_117\n",
      "442 conv2d_120\n",
      "443 batch_normalization_117\n",
      "444 batch_normalization_120\n",
      "445 activation_117\n",
      "446 activation_120\n",
      "447 block17_11_mixed\n",
      "448 block17_11_conv\n",
      "449 block17_11\n",
      "450 block17_11_ac\n",
      "451 conv2d_122\n",
      "452 batch_normalization_122\n",
      "453 activation_122\n",
      "454 conv2d_123\n",
      "455 batch_normalization_123\n",
      "456 activation_123\n",
      "457 conv2d_121\n",
      "458 conv2d_124\n",
      "459 batch_normalization_121\n",
      "460 batch_normalization_124\n",
      "461 activation_121\n",
      "462 activation_124\n",
      "463 block17_12_mixed\n",
      "464 block17_12_conv\n",
      "465 block17_12\n",
      "466 block17_12_ac\n",
      "467 conv2d_126\n",
      "468 batch_normalization_126\n",
      "469 activation_126\n",
      "470 conv2d_127\n",
      "471 batch_normalization_127\n",
      "472 activation_127\n",
      "473 conv2d_125\n",
      "474 conv2d_128\n",
      "475 batch_normalization_125\n",
      "476 batch_normalization_128\n",
      "477 activation_125\n",
      "478 activation_128\n",
      "479 block17_13_mixed\n",
      "480 block17_13_conv\n",
      "481 block17_13\n",
      "482 block17_13_ac\n",
      "483 conv2d_130\n",
      "484 batch_normalization_130\n",
      "485 activation_130\n",
      "486 conv2d_131\n",
      "487 batch_normalization_131\n",
      "488 activation_131\n",
      "489 conv2d_129\n",
      "490 conv2d_132\n",
      "491 batch_normalization_129\n",
      "492 batch_normalization_132\n",
      "493 activation_129\n",
      "494 activation_132\n",
      "495 block17_14_mixed\n",
      "496 block17_14_conv\n",
      "497 block17_14\n",
      "498 block17_14_ac\n",
      "499 conv2d_134\n",
      "500 batch_normalization_134\n",
      "501 activation_134\n",
      "502 conv2d_135\n",
      "503 batch_normalization_135\n",
      "504 activation_135\n",
      "505 conv2d_133\n",
      "506 conv2d_136\n",
      "507 batch_normalization_133\n",
      "508 batch_normalization_136\n",
      "509 activation_133\n",
      "510 activation_136\n",
      "511 block17_15_mixed\n",
      "512 block17_15_conv\n",
      "513 block17_15\n",
      "514 block17_15_ac\n",
      "515 conv2d_138\n",
      "516 batch_normalization_138\n",
      "517 activation_138\n",
      "518 conv2d_139\n",
      "519 batch_normalization_139\n",
      "520 activation_139\n",
      "521 conv2d_137\n",
      "522 conv2d_140\n",
      "523 batch_normalization_137\n",
      "524 batch_normalization_140\n",
      "525 activation_137\n",
      "526 activation_140\n",
      "527 block17_16_mixed\n",
      "528 block17_16_conv\n",
      "529 block17_16\n",
      "530 block17_16_ac\n",
      "531 conv2d_142\n",
      "532 batch_normalization_142\n",
      "533 activation_142\n",
      "534 conv2d_143\n",
      "535 batch_normalization_143\n",
      "536 activation_143\n",
      "537 conv2d_141\n",
      "538 conv2d_144\n",
      "539 batch_normalization_141\n",
      "540 batch_normalization_144\n",
      "541 activation_141\n",
      "542 activation_144\n",
      "543 block17_17_mixed\n",
      "544 block17_17_conv\n",
      "545 block17_17\n",
      "546 block17_17_ac\n",
      "547 conv2d_146\n",
      "548 batch_normalization_146\n",
      "549 activation_146\n",
      "550 conv2d_147\n",
      "551 batch_normalization_147\n",
      "552 activation_147\n",
      "553 conv2d_145\n",
      "554 conv2d_148\n",
      "555 batch_normalization_145\n",
      "556 batch_normalization_148\n",
      "557 activation_145\n",
      "558 activation_148\n",
      "559 block17_18_mixed\n",
      "560 block17_18_conv\n",
      "561 block17_18\n",
      "562 block17_18_ac\n",
      "563 conv2d_150\n",
      "564 batch_normalization_150\n",
      "565 activation_150\n",
      "566 conv2d_151\n",
      "567 batch_normalization_151\n",
      "568 activation_151\n",
      "569 conv2d_149\n",
      "570 conv2d_152\n",
      "571 batch_normalization_149\n",
      "572 batch_normalization_152\n",
      "573 activation_149\n",
      "574 activation_152\n",
      "575 block17_19_mixed\n",
      "576 block17_19_conv\n",
      "577 block17_19\n",
      "578 block17_19_ac\n",
      "579 conv2d_154\n",
      "580 batch_normalization_154\n",
      "581 activation_154\n",
      "582 conv2d_155\n",
      "583 batch_normalization_155\n",
      "584 activation_155\n",
      "585 conv2d_153\n",
      "586 conv2d_156\n",
      "587 batch_normalization_153\n",
      "588 batch_normalization_156\n",
      "589 activation_153\n",
      "590 activation_156\n",
      "591 block17_20_mixed\n",
      "592 block17_20_conv\n",
      "593 block17_20\n",
      "594 block17_20_ac\n",
      "595 conv2d_161\n",
      "596 batch_normalization_161\n",
      "597 activation_161\n",
      "598 conv2d_157\n",
      "599 conv2d_159\n",
      "600 conv2d_162\n",
      "601 batch_normalization_157\n",
      "602 batch_normalization_159\n",
      "603 batch_normalization_162\n",
      "604 activation_157\n",
      "605 activation_159\n",
      "606 activation_162\n",
      "607 conv2d_158\n",
      "608 conv2d_160\n",
      "609 conv2d_163\n",
      "610 batch_normalization_158\n",
      "611 batch_normalization_160\n",
      "612 batch_normalization_163\n",
      "613 activation_158\n",
      "614 activation_160\n",
      "615 activation_163\n",
      "616 max_pooling2d_4\n",
      "617 mixed_7a\n",
      "618 conv2d_165\n",
      "619 batch_normalization_165\n",
      "620 activation_165\n",
      "621 conv2d_166\n",
      "622 batch_normalization_166\n",
      "623 activation_166\n",
      "624 conv2d_164\n",
      "625 conv2d_167\n",
      "626 batch_normalization_164\n",
      "627 batch_normalization_167\n",
      "628 activation_164\n",
      "629 activation_167\n",
      "630 block8_1_mixed\n",
      "631 block8_1_conv\n",
      "632 block8_1\n",
      "633 block8_1_ac\n",
      "634 conv2d_169\n",
      "635 batch_normalization_169\n",
      "636 activation_169\n",
      "637 conv2d_170\n",
      "638 batch_normalization_170\n",
      "639 activation_170\n",
      "640 conv2d_168\n",
      "641 conv2d_171\n",
      "642 batch_normalization_168\n",
      "643 batch_normalization_171\n",
      "644 activation_168\n",
      "645 activation_171\n",
      "646 block8_2_mixed\n",
      "647 block8_2_conv\n",
      "648 block8_2\n",
      "649 block8_2_ac\n",
      "650 conv2d_173\n",
      "651 batch_normalization_173\n",
      "652 activation_173\n",
      "653 conv2d_174\n",
      "654 batch_normalization_174\n",
      "655 activation_174\n",
      "656 conv2d_172\n",
      "657 conv2d_175\n",
      "658 batch_normalization_172\n",
      "659 batch_normalization_175\n",
      "660 activation_172\n",
      "661 activation_175\n",
      "662 block8_3_mixed\n",
      "663 block8_3_conv\n",
      "664 block8_3\n",
      "665 block8_3_ac\n",
      "666 conv2d_177\n",
      "667 batch_normalization_177\n",
      "668 activation_177\n",
      "669 conv2d_178\n",
      "670 batch_normalization_178\n",
      "671 activation_178\n",
      "672 conv2d_176\n",
      "673 conv2d_179\n",
      "674 batch_normalization_176\n",
      "675 batch_normalization_179\n",
      "676 activation_176\n",
      "677 activation_179\n",
      "678 block8_4_mixed\n",
      "679 block8_4_conv\n",
      "680 block8_4\n",
      "681 block8_4_ac\n",
      "682 conv2d_181\n",
      "683 batch_normalization_181\n",
      "684 activation_181\n",
      "685 conv2d_182\n",
      "686 batch_normalization_182\n",
      "687 activation_182\n",
      "688 conv2d_180\n",
      "689 conv2d_183\n",
      "690 batch_normalization_180\n",
      "691 batch_normalization_183\n",
      "692 activation_180\n",
      "693 activation_183\n",
      "694 block8_5_mixed\n",
      "695 block8_5_conv\n",
      "696 block8_5\n",
      "697 block8_5_ac\n",
      "698 conv2d_185\n",
      "699 batch_normalization_185\n",
      "700 activation_185\n",
      "701 conv2d_186\n",
      "702 batch_normalization_186\n",
      "703 activation_186\n",
      "704 conv2d_184\n",
      "705 conv2d_187\n",
      "706 batch_normalization_184\n",
      "707 batch_normalization_187\n",
      "708 activation_184\n",
      "709 activation_187\n",
      "710 block8_6_mixed\n",
      "711 block8_6_conv\n",
      "712 block8_6\n",
      "713 block8_6_ac\n",
      "714 conv2d_189\n",
      "715 batch_normalization_189\n",
      "716 activation_189\n",
      "717 conv2d_190\n",
      "718 batch_normalization_190\n",
      "719 activation_190\n",
      "720 conv2d_188\n",
      "721 conv2d_191\n",
      "722 batch_normalization_188\n",
      "723 batch_normalization_191\n",
      "724 activation_188\n",
      "725 activation_191\n",
      "726 block8_7_mixed\n",
      "727 block8_7_conv\n",
      "728 block8_7\n",
      "729 block8_7_ac\n",
      "730 conv2d_193\n",
      "731 batch_normalization_193\n",
      "732 activation_193\n",
      "733 conv2d_194\n",
      "734 batch_normalization_194\n",
      "735 activation_194\n",
      "736 conv2d_192\n",
      "737 conv2d_195\n",
      "738 batch_normalization_192\n",
      "739 batch_normalization_195\n",
      "740 activation_192\n",
      "741 activation_195\n",
      "742 block8_8_mixed\n",
      "743 block8_8_conv\n",
      "744 block8_8\n",
      "745 block8_8_ac\n",
      "746 conv2d_197\n",
      "747 batch_normalization_197\n",
      "748 activation_197\n",
      "749 conv2d_198\n",
      "750 batch_normalization_198\n",
      "751 activation_198\n",
      "752 conv2d_196\n",
      "753 conv2d_199\n",
      "754 batch_normalization_196\n",
      "755 batch_normalization_199\n",
      "756 activation_196\n",
      "757 activation_199\n",
      "758 block8_9_mixed\n",
      "759 block8_9_conv\n",
      "760 block8_9\n",
      "761 block8_9_ac\n",
      "762 conv2d_201\n",
      "763 batch_normalization_201\n",
      "764 activation_201\n",
      "765 conv2d_202\n",
      "766 batch_normalization_202\n",
      "767 activation_202\n",
      "768 conv2d_200\n",
      "769 conv2d_203\n",
      "770 batch_normalization_200\n",
      "771 batch_normalization_203\n",
      "772 activation_200\n",
      "773 activation_203\n",
      "774 block8_10_mixed\n",
      "775 block8_10_conv\n",
      "776 block8_10\n",
      "777 conv_7b\n",
      "778 conv_7b_bn\n",
      "779 conv_7b_ac\n",
      "780 global_average_pooling2d_1\n",
      "781 dense_1\n",
      "782 dense_2\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_94vieaG3Fr"
   },
   "outputs": [],
   "source": [
    "#   first: train only the top layers (which were randomly initialized)\n",
    "#   i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihuqYwy6G3Ft"
   },
   "outputs": [],
   "source": [
    "y_train_one_hot = tf.one_hot( y_train, n_classes ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8ws43dfG3Fz"
   },
   "outputs": [],
   "source": [
    "data_train_gen = data_generator(sess, X_train, y_train_one_hot )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "R3SHSVJPG3F2",
    "outputId": "159b256b-3aa7-4ba0-8780-592914d877d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "782/781 [==============================] - 171s 219ms/step - loss: 0.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2767d5ea198>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the new data for a \"few\" epochs\n",
    "model.fit_generator(data_train_gen(), n_training/batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bV_ICBeG3F4"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "os4joPMyG3F5"
   },
   "outputs": [],
   "source": [
    "images_resized = sess.run(tf_resize_op, {batch_of_images_placeholder: X_test})\n",
    "images = preprocess_input(images_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GkZqPEjG3F8"
   },
   "outputs": [],
   "source": [
    "result = model.predict(images, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdlJp8UNG3F_"
   },
   "outputs": [],
   "source": [
    "y_pred = [ np.argmax( result[i] ) for i in range(n_testing) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BTf-rQJtG3GA",
    "outputId": "f8c47425-9260-47b5-cdb4-6e0aad15c131"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum( y_pred == y_test ) / n_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jALgdX6oG3GC"
   },
   "source": [
    "## Train again a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8dvNV9oG3GD"
   },
   "outputs": [],
   "source": [
    "# train the model on the new data for a \"few\" epochs\n",
    "# model.fit_generator(data_train_gen(), n_training/batch_size, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTIbfPBXG3GG"
   },
   "source": [
    "## Validate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "GXwSBadkG3GH",
    "outputId": "9e8793ff-7bf8-4d2e-d622-788654a37f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 38s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7323"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(images, verbose=1)\n",
    "y_pred = [ np.argmax( result[i] ) for i in range(n_testing) ]\n",
    "np.sum( y_pred == y_test ) / n_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngHyoMh-G3GJ"
   },
   "source": [
    "## Train more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oqz4uWazG3GK"
   },
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-vs-fxeG3GN"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:16]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[16:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfWjZTL4G3GO"
   },
   "outputs": [],
   "source": [
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1147
    },
    "colab_type": "code",
    "id": "NKZBtzsTG3GQ",
    "outputId": "d5ea68b4-5378-4f03-e81d-ed114040f60a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/781 [==============================] - 451s 576ms/step - loss: 0.2688\n",
      "Epoch 2/10\n",
      "782/781 [==============================] - 447s 572ms/step - loss: 0.0647\n",
      "Epoch 3/10\n",
      "782/781 [==============================] - 446s 570ms/step - loss: 0.0170\n",
      "Epoch 4/10\n",
      "782/781 [==============================] - 453s 580ms/step - loss: 0.0059\n",
      "Epoch 5/10\n",
      "782/781 [==============================] - 455s 581ms/step - loss: 0.0029\n",
      "Epoch 6/10\n",
      "782/781 [==============================] - 455s 582ms/step - loss: 0.0018\n",
      "Epoch 7/10\n",
      "782/781 [==============================] - 456s 584ms/step - loss: 0.0011\n",
      "Epoch 8/10\n",
      "782/781 [==============================] - 451s 577ms/step - loss: 7.8778e-04\n",
      "Epoch 9/10\n",
      "782/781 [==============================] - 466s 596ms/step - loss: 6.1613e-04\n",
      "Epoch 10/10\n",
      "782/781 [==============================] - 452s 578ms/step - loss: 5.0233e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2767d700b38>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(data_train_gen(), n_training/batch_size, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MypxJYRsG3GU"
   },
   "outputs": [],
   "source": [
    "# model.fit_generator(data_train_gen(), n_training/batch_size, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "P0ObZnPsG3GX"
   },
   "source": [
    "## Validate tuned network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "iXbIasGuG3GY",
    "outputId": "469c9573-ba89-4ce5-d211-583193eabebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 43s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9383"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(images, verbose=1)\n",
    "y_pred = [ np.argmax( result[i] ) for i in range(n_testing) ]\n",
    "np.sum( y_pred == y_test ) / n_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0vga2NZG3Gb"
   },
   "source": [
    "So we obtained 93.83% on testing dataset"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fine_tunning_keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
